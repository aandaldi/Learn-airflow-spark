# Pyspark with Airflow for simple case using IDX data

### Tools

- Apache Spark using Pyspark as ETL framework
- Apache Airflow as scheduler
- Docker and Docker Compose for deploy Airflow environment
- need to install postgres on your local env or docker env (in this compose there's no cover postgres container) * read https://hub.docker.com/_/postgres for postgres docker installation step by step
